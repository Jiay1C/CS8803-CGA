{"cells":[{"cell_type":"markdown","id":"e7328294","metadata":{"id":"e7328294"},"source":["## Step 1.1: Install Packages and Libraries"]},{"cell_type":"code","execution_count":2,"id":"c9815e45-57bf-4565-8670-6d91c8bdb35f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c9815e45-57bf-4565-8670-6d91c8bdb35f","outputId":"fafac3a5-8f5b-4c47-84ef-5005313e422e","executionInfo":{"status":"ok","timestamp":1740951042166,"user_tz":300,"elapsed":8233,"user":{"displayName":"Jiayi Chen","userId":"08311739456871249100"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: mesh_to_sdf in /usr/local/lib/python3.11/dist-packages (0.0.15)\n","Requirement already satisfied: pyopengl in /usr/local/lib/python3.11/dist-packages (from mesh_to_sdf) (3.1.0)\n","Requirement already satisfied: pyrender in /usr/local/lib/python3.11/dist-packages (from mesh_to_sdf) (0.1.45)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from mesh_to_sdf) (0.25.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from mesh_to_sdf) (1.6.1)\n","Requirement already satisfied: freetype-py in /usr/local/lib/python3.11/dist-packages (from pyrender->mesh_to_sdf) (2.5.1)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (from pyrender->mesh_to_sdf) (2.37.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pyrender->mesh_to_sdf) (3.4.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pyrender->mesh_to_sdf) (1.26.4)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from pyrender->mesh_to_sdf) (11.1.0)\n","Requirement already satisfied: pyglet>=1.4.10 in /usr/local/lib/python3.11/dist-packages (from pyrender->mesh_to_sdf) (2.1.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pyrender->mesh_to_sdf) (1.13.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from pyrender->mesh_to_sdf) (1.17.0)\n","Requirement already satisfied: trimesh in /usr/local/lib/python3.11/dist-packages (from pyrender->mesh_to_sdf) (4.6.4)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->mesh_to_sdf) (2025.1.10)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->mesh_to_sdf) (24.2)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->mesh_to_sdf) (0.4)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->mesh_to_sdf) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->mesh_to_sdf) (3.5.0)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n","  xserver-common\n","The following NEW packages will be installed:\n","  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n","  xserver-common xvfb\n","0 upgraded, 9 newly installed, 0 to remove and 51 not upgraded.\n","Need to get 7,814 kB of archives.\n","After this operation, 12.0 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.13 [29.1 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.13 [863 kB]\n","Fetched 7,814 kB in 0s (17.6 MB/s)\n","Selecting previously unselected package libfontenc1:amd64.\n","(Reading database ... 124926 files and directories currently installed.)\n","Preparing to unpack .../0-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n","Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n","Selecting previously unselected package libxfont2:amd64.\n","Preparing to unpack .../1-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n","Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n","Selecting previously unselected package libxkbfile1:amd64.\n","Preparing to unpack .../2-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n","Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n","Selecting previously unselected package x11-xkb-utils.\n","Preparing to unpack .../3-x11-xkb-utils_7.7+5build4_amd64.deb ...\n","Unpacking x11-xkb-utils (7.7+5build4) ...\n","Selecting previously unselected package xfonts-encodings.\n","Preparing to unpack .../4-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n","Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n","Selecting previously unselected package xfonts-utils.\n","Preparing to unpack .../5-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n","Unpacking xfonts-utils (1:7.7+6build2) ...\n","Selecting previously unselected package xfonts-base.\n","Preparing to unpack .../6-xfonts-base_1%3a1.0.5_all.deb ...\n","Unpacking xfonts-base (1:1.0.5) ...\n","Selecting previously unselected package xserver-common.\n","Preparing to unpack .../7-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.13_all.deb ...\n","Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.13) ...\n","Selecting previously unselected package xvfb.\n","Preparing to unpack .../8-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.13_amd64.deb ...\n","Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.13) ...\n","Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n","Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n","Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n","Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n","Setting up x11-xkb-utils (7.7+5build4) ...\n","Setting up xfonts-utils (1:7.7+6build2) ...\n","Setting up xfonts-base (1:1.0.5) ...\n","Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.13) ...\n","Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.13) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n","\n","Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.11/dist-packages (3.0)\n"]}],"source":["!pip install mesh_to_sdf\n","!apt-get install xvfb\n","!pip install pyvirtualdisplay"]},{"cell_type":"code","execution_count":3,"id":"78dd34ee-1d7b-47f7-b1c0-9b8bebe3c410","metadata":{"id":"78dd34ee-1d7b-47f7-b1c0-9b8bebe3c410","executionInfo":{"status":"ok","timestamp":1740951045883,"user_tz":300,"elapsed":2503,"user":{"displayName":"Jiayi Chen","userId":"08311739456871249100"}}},"outputs":[],"source":["\"\"\"\n","Step 1.1: Install Necessary Packages and Libraries\n","\"\"\"\n","\n","from IPython import get_ipython\n","from IPython.display import display\n","\n","import torch\n","from torch import nn\n","from mesh_to_sdf import sample_sdf_near_surface\n","import trimesh\n","from torch.utils.data import DataLoader, Dataset\n","import numpy as np\n","from math import sqrt\n","from pyvirtualdisplay import Display\n","display = Display(visible=0, size=(1400, 900))\n","display.start()\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.mplot3d import Axes3D\n"]},{"cell_type":"markdown","id":"3476f642","metadata":{"id":"3476f642"},"source":["## Step 1.2 Prepare Training Dataset"]},{"cell_type":"code","execution_count":4,"id":"0cb098a6-acb2-435e-affd-1f94d2385ec7","metadata":{"id":"0cb098a6-acb2-435e-affd-1f94d2385ec7","executionInfo":{"status":"ok","timestamp":1740951046489,"user_tz":300,"elapsed":3,"user":{"displayName":"Jiayi Chen","userId":"08311739456871249100"}}},"outputs":[],"source":["\"\"\"\n","Step 1.2: Prepare the Training Dataset from Input Mesh\n","\"\"\"\n","\n","class NeuralSDFDataset(Dataset):\n","    def __init__(self, mesh_path, sample_num, device='cuda'):\n","        \"\"\"\n","        In this function, we first use a package called `trimesh` (it's already imported in Step 1.1) to load an `.obj` file with path <code>mesh_path</code>\n","        We then sample sample_num points around the surface by calling method `sample_sdf_near_surface`.\n","\n","        Your task is to convert the sampled points and their sdf values (with the type of `numpy ndarray`) to torch tensors by calling the `torch.from_numpy` function.\n","        After conversion, you will send those tensors to CUDA GPU by calling the `.to(device)` function.\n","        The converted device tensors should be stored in self.points and self.sdf in separate.\n","        \"\"\"\n","        mesh = trimesh.load(mesh_path)\n","        points, sdf = sample_sdf_near_surface(mesh, number_of_points=sample_num)\n","\n","        ### you implementation starts\n","\n","        self.points = torch.from_numpy(points).to(device)\n","        self.sdf = torch.from_numpy(sdf).to(device)\n","\n","        ### you implementation ends\n","\n","\n","    def __len__(self):\n","        return 1 # we are not using this\n","\n","    def __getitem__(self, idx):\n","        return self.points, self.sdf"]},{"cell_type":"code","execution_count":5,"id":"c1e00e7e","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":388},"id":"c1e00e7e","executionInfo":{"status":"error","timestamp":1740951059760,"user_tz":300,"elapsed":11871,"user":{"displayName":"Jiayi Chen","userId":"08311739456871249100"}},"outputId":"265ed3ea-785f-4982-bed1-c10ee6766b02"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-90d72e7433be>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mmesh_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cow.obj\"\u001b[0m \u001b[0;31m### Change to bunny.obj if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0msdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralSDFDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0msdf_loader_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdf_loader_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-adddd5c8eeef>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mesh_path, sample_num, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m### you implementation starts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"]}],"source":["\"\"\"\n","This block is a checkpoint for you Step 1.2 implementation. Run the block to check the plot of the sample point distribution and make sure it is consistent with the input shape.\n","There is no implementation requirement within this block.\n","\"\"\"\n","\n","### Helper method for test result of the sampled points from your dataset class.\n","def test_dataset(sdf_loader_test):\n","  points, sdf = next(iter(sdf_loader_test))\n","  points =  points.cpu().detach().numpy().squeeze(0)\n","  sdf = sdf.cpu().detach().numpy().squeeze()\n","  norm = plt.Normalize(vmin=np.min(sdf), vmax=np.max(sdf))\n","  colors = plt.cm.coolwarm(norm(sdf))\n","  fig = plt.figure(figsize=(8, 6))\n","  ax = fig.add_subplot(111, projection='3d')\n","\n","  sc = ax.scatter(points[:, 0], points[:, 1], points[:, 2], c=sdf, cmap='coolwarm', marker='o')\n","\n","  cbar = plt.colorbar(sc, ax=ax, shrink=0.5)\n","  cbar.set_label(\"SDF Value\")\n","\n","  ax.set_xlabel(\"X\")\n","  ax.set_ylabel(\"Y\")\n","  ax.set_zlabel(\"Z\")\n","  ax.set_title(\"3D Point Cloud Visualization with SDF Values\")\n","  ax.view_init(elev=0, azim=0)\n","  plt.show()\n","\n","\n","sample_num = 10000\n","device='cuda'\n","mesh_path=\"cow.obj\" ### Change to bunny.obj if needed.\n","\n","sdf_test = NeuralSDFDataset(mesh_path, sample_num, device=device)\n","sdf_loader_test = DataLoader(sdf_test, num_workers=0)\n","test_dataset(sdf_loader_test)"]},{"cell_type":"markdown","id":"3c3d9f5e","metadata":{"id":"3c3d9f5e"},"source":["## Step 1.3 Network Structure"]},{"cell_type":"code","execution_count":7,"id":"db29c56f-6b6c-47f6-8ba5-c40fb6741742","metadata":{"id":"db29c56f-6b6c-47f6-8ba5-c40fb6741742","executionInfo":{"status":"ok","timestamp":1740950417811,"user_tz":300,"elapsed":4,"user":{"displayName":"Jiayi Chen","userId":"08311739456871249100"}}},"outputs":[],"source":["\"\"\"\n","Step 1.3: Neural Network Structure for SDF Representation\n","\"\"\"\n","\n","class SineLayer(nn.Module):\n","    \"\"\"\n","    Default sin activation frequency w0 is set to be 30, feel free to play with it.\n","    However, we set this to be 15 by default due to our network is much smaller that suffers from learning high frequency features.\n","    If you have time, make the hidden layers to 512 width with 5 depth, then checkout the difference.\n","\n","    By default, the weights for the first layer are initialized differently as suggested in Sec.3.2 in the original paper. We use is_first flag to\n","    check whether we should init the weights differently.\n","\n","    We use linear layer as the last layer without any activation functions since SDF values shouldn't be limited to a certain range.\n","    We use is_last flag to check if we should use activation functions or not.\n","    \"\"\"\n","\n","    def __init__(self, in_features, out_features, bias=True,\n","                 is_first=False, is_last=False, w0=15, skip_weight=1):\n","        \"\"\"\n","        In this function, you are tasked to initialize the fully-connectd layer self.fc using the feature vectors with their sizes specified by in_featuers and out_features\n","        \"\"\"\n","\n","        super().__init__()\n","        self.w0 = w0                         # a float specifying the default frequency in activation function\n","        self.is_first = is_first             # a boolean flag indicating if the layer is the first layer\n","        self.is_last = is_last               # a boolean flag indicating if the layer is the last layer\n","        self.skip_weight = skip_weight       # a float weight controlling skip connection\n","        self.in_features = in_features       # an integer specifying the size of the input feature vector\n","        self.out_features = out_features     # an integer specifying the size of the output feature vector\n","        self.fc = None                       # fully connected layer; None as default\n","\n","        ### your implementation starts\n","\n","        self.fc = nn.Linear(in_features, out_features, bias=bias)\n","\n","        ### your implementation ends\n","\n","        self.init_weights()\n","\n","    def init_weights(self):\n","        \"\"\"\n","        This function initializes the weights for the first layer and other layers (see details in the Deep SDF paper Sec.3.2).\n","        No implementation is required in this function.\n","        \"\"\"\n","        with torch.no_grad():\n","            if self.is_first:\n","                self.fc.weight.uniform_(-1. / self.in_features,\n","                                             1. / self.in_features)\n","            else:\n","                self.fc.weight.uniform_(-np.sqrt(6 / self.in_features) / self.w0,\n","                                             np.sqrt(6 / self.in_features) / self.w0)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        You are tasked to implement the activation function by using the output of the fully connected layer taking x.\n","        The implementation should consists of three cases: the first layer, the last layer, and the intermediate layer(s).\n","            - If the layer is the first layer, you should apply the sine activation function to the output of the fully connected layer with w0 as its frequency;\n","            - If the layer is the last layer, you should take the output of the fully connected layer as the final output;\n","            - If the layer is an intermediate layer, you should add the output from the sine activation function weighted by skip_weight to the original x.\n","        \"\"\"\n","        ### your implementation starts\n","\n","        fc_output = self.fc(x)\n","\n","        if self.is_first:\n","            return torch.sin(self.w0 * fc_output)\n","        elif self.is_last:\n","            return fc_output\n","        else:\n","            return torch.sin(self.w0 * fc_output) / self.skip_weight + x\n","\n","\n","        ### your implementation ends\n","\n","class NeuralSDF(nn.Module):\n","    def __init__(self, in_features, hidden_features, hidden_layers, out_features, w0=30):\n","        super().__init__()\n","\n","        \"\"\"\n","        You are tasked to initialize all the layers in the neural network, including the first layer, the intermediate layer(s), and the last layer.\n","        The initialized network layers will be stored in the list of nn.\n","        Make sure to use the input arguments of the init function when initializing these layers.\n","        \"\"\"\n","\n","        self.network = []                               # a list storing all the layers; empty by default\n","        self.w0 = w0                                    # a float specifying the activation function frequency\n","        self.hidden_features = hidden_features          # an integer specifying the size of the hidden-layer feature vector\n","        self.hidden_layers = hidden_layers              # an integer specifying specifying the number of hidden layers\n","        self.in_features = in_features                  # an integer specifying the size of the input feature vector\n","        self.out_features = out_features                # an integer specifying the size of the output feature vector\n","\n","        ### your implementation starts\n","\n","        self.network.append(SineLayer(in_features=in_features, out_features=hidden_features, is_first=True, w0=w0))\n","        for i in range(self.hidden_layers):\n","            self.network.append(SineLayer(in_features=hidden_features, out_features=hidden_features, w0=w0, skip_weight=sqrt(i+1)))\n","        self.network.append(SineLayer(in_features=hidden_features, out_features=out_features, is_last=True, w0=w0))\n","\n","        ### your implementation ends\n","\n","        self.network = nn.Sequential(*self.network)\n","\n","    def forward(self, x):\n","        output = self.network(x)\n","        return output"]},{"cell_type":"markdown","id":"9c90b11e","metadata":{"id":"9c90b11e"},"source":["## Step 1.4 Train Your Network"]},{"cell_type":"code","execution_count":8,"id":"fb654774-d60f-4f06-b374-9b5cc8ebe840","metadata":{"id":"fb654774-d60f-4f06-b374-9b5cc8ebe840","executionInfo":{"status":"ok","timestamp":1740950420177,"user_tz":300,"elapsed":2,"user":{"displayName":"Jiayi Chen","userId":"08311739456871249100"}}},"outputs":[],"source":["\"\"\"\n","Step 1.4: Train Your Neural Network with Adam Optimizer\n","\"\"\"\n","def train_neuralSDF(dataloader, hidden_features, hidden_layers, w0, lr=1e-4, iterations=10000, device='cuda'):\n","    \"\"\"\n","    You are tasked to implement the training loop of the neural network.\n","    For each epoch, you will start with a zero gradient and use the Mean Squared Loss (MSE) as your loss function.\n","    Then, you need to propagate the loss backward and run the optimization step function provided by the optimizer.\n","    \"\"\"\n","\n","    model = NeuralSDF(in_features=3, out_features=1, hidden_features=hidden_features, hidden_layers=hidden_layers, w0=w0).to(device)\n","    optimizer = torch.optim.Adam(lr=lr, params=model.parameters(), weight_decay=.0)\n","    data, labels = next(iter(dataloader))\n","\n","    for epoch in range(iterations):\n","\n","        ### your implementation starts\n","\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = nn.MSELoss()(output[0].squeeze(dim=1), labels[0])\n","        loss.backward()\n","        optimizer.step()\n","\n","        ### your implementation ends\n","\n","        if epoch % 100 == 0:\n","            print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n","\n","    return model"]},{"cell_type":"code","execution_count":9,"id":"9195eb13-77a7-45b5-baf1-d5b471cd4828","metadata":{"id":"9195eb13-77a7-45b5-baf1-d5b471cd4828","executionInfo":{"status":"error","timestamp":1740950449152,"user_tz":300,"elapsed":12786,"user":{"displayName":"Jiayi Chen","userId":"08311739456871249100"}},"colab":{"base_uri":"https://localhost:8080/","height":370},"outputId":"e688440f-e18b-432e-e063-aad91b7dd881"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-fac829a3e26a>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmesh_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cow.obj\"\u001b[0m \u001b[0;31m### mesh path to your mesh,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0msdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralSDFDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0msdfloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-adddd5c8eeef>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mesh_path, sample_num, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m### you implementation starts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"]}],"source":["\"\"\"\n","sample_num: total points sampled (feel free to increase this if needed)\n","mesh_path: relative path to .obj file location\n","\"\"\"\n","\n","sample_num = 30000  ### total number of points sampled as training points, feel free to change this.\n","device='cuda'\n","mesh_path=\"cow.obj\" ### mesh path to your mesh,\n","\n","sdf = NeuralSDFDataset(mesh_path, sample_num, device=device)\n","sdfloader = DataLoader(sdf, num_workers=0)"]},{"cell_type":"code","source":["\"\"\"\n","hidden_features: hidden layer width.\n","hidden_layers: hidden layer depth.\n","w0: Activation frequency. We suggest 15 for our given examples.\n","\n","Feel free to play around with these parameters.\n","\"\"\"\n","hidden_features = 16 ### hidden layer width, feel free to change\n","hidden_layers = 2 ### hidden layer depth, feel free to change\n","w0 = 15 ### activation function frequency, feel free to change\n","iterations = 20000 ### total number of training iterations, feel free to change\n","lr = 1e-4 ### learning rate, feel free to change\n","\n","neural_sdf = train_neuralSDF(sdfloader, hidden_features = hidden_features, hidden_layers = hidden_layers, w0 = w0, lr=lr, iterations=iterations, device=device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FgXCYn9xRnRF","executionInfo":{"status":"ok","timestamp":1739466852677,"user_tz":300,"elapsed":44347,"user":{"displayName":"Jiayi Chen","userId":"08311739456871249100"}},"outputId":"3b639c84-4306-4c95-8ee9-49ab40cf6d54"},"id":"FgXCYn9xRnRF","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 0.011831598356366158\n","Epoch 101, Loss: 0.0032816838938742876\n","Epoch 201, Loss: 0.0018407984171062708\n","Epoch 301, Loss: 0.0011516251834109426\n","Epoch 401, Loss: 0.0007419137400574982\n","Epoch 501, Loss: 0.0005059224786236882\n","Epoch 601, Loss: 0.00035448314156383276\n","Epoch 701, Loss: 0.00026222324231639504\n","Epoch 801, Loss: 0.00021133317204657942\n","Epoch 901, Loss: 0.0001796564756659791\n","Epoch 1001, Loss: 0.00015751435421407223\n","Epoch 1101, Loss: 0.0001407396193826571\n","Epoch 1201, Loss: 0.00012738100485876203\n","Epoch 1301, Loss: 0.00011639551667030901\n","Epoch 1401, Loss: 0.00010712462972151116\n","Epoch 1501, Loss: 9.912146924762055e-05\n","Epoch 1601, Loss: 9.208785922965035e-05\n","Epoch 1701, Loss: 8.583841554354876e-05\n","Epoch 1801, Loss: 8.027426520129666e-05\n","Epoch 1901, Loss: 7.534131873399019e-05\n","Epoch 2001, Loss: 7.097789784893394e-05\n","Epoch 2101, Loss: 6.709491572109982e-05\n","Epoch 2201, Loss: 6.35965188848786e-05\n","Epoch 2301, Loss: 6.040644439053722e-05\n","Epoch 2401, Loss: 5.74771584069822e-05\n","Epoch 2501, Loss: 5.478401726577431e-05\n","Epoch 2601, Loss: 5.2311206673039123e-05\n","Epoch 2701, Loss: 5.003805927117355e-05\n","Epoch 2801, Loss: 4.793645712197758e-05\n","Epoch 2901, Loss: 4.598160012392327e-05\n","Epoch 3001, Loss: 4.416182855493389e-05\n","Epoch 3101, Loss: 4.2475909140193835e-05\n","Epoch 3201, Loss: 4.0922641346696764e-05\n","Epoch 3301, Loss: 3.9495873352279887e-05\n","Epoch 3401, Loss: 3.8185120502021164e-05\n","Epoch 3501, Loss: 3.697706415550783e-05\n","Epoch 3601, Loss: 3.5856843169312924e-05\n","Epoch 3701, Loss: 3.48095090885181e-05\n","Epoch 3801, Loss: 3.382213617442176e-05\n","Epoch 3901, Loss: 3.289061351097189e-05\n","Epoch 4001, Loss: 3.201096842531115e-05\n","Epoch 4101, Loss: 3.117269807262346e-05\n","Epoch 4201, Loss: 3.0885799787938595e-05\n","Epoch 4301, Loss: 2.964446321129799e-05\n","Epoch 4401, Loss: 2.894285717047751e-05\n","Epoch 4501, Loss: 2.828213655448053e-05\n","Epoch 4601, Loss: 2.765283170447219e-05\n","Epoch 4701, Loss: 2.705782935663592e-05\n","Epoch 4801, Loss: 2.6485877242521383e-05\n","Epoch 4901, Loss: 2.5937752070603892e-05\n","Epoch 5001, Loss: 2.5414312403881922e-05\n","Epoch 5101, Loss: 2.4914928872021846e-05\n","Epoch 5201, Loss: 2.449783823976759e-05\n","Epoch 5301, Loss: 2.398432116024196e-05\n","Epoch 5401, Loss: 2.358345409447793e-05\n","Epoch 5501, Loss: 2.312524702574592e-05\n","Epoch 5601, Loss: 2.272027086291928e-05\n","Epoch 5701, Loss: 2.232284350611735e-05\n","Epoch 5801, Loss: 2.1941899831290357e-05\n","Epoch 5901, Loss: 2.1584040950983763e-05\n","Epoch 6001, Loss: 2.121943180100061e-05\n","Epoch 6101, Loss: 2.088938890665304e-05\n","Epoch 6201, Loss: 2.064259933831636e-05\n","Epoch 6301, Loss: 2.0276675058994442e-05\n","Epoch 6401, Loss: 1.9996101400465705e-05\n","Epoch 6501, Loss: 1.97383724298561e-05\n","Epoch 6601, Loss: 1.962508395081386e-05\n","Epoch 6701, Loss: 1.9286866518086754e-05\n","Epoch 6801, Loss: 1.9042145140701905e-05\n","Epoch 6901, Loss: 1.8834049114957452e-05\n","Epoch 7001, Loss: 1.8636821550899185e-05\n","Epoch 7101, Loss: 1.8444183297106065e-05\n","Epoch 7201, Loss: 1.8259963326272555e-05\n","Epoch 7301, Loss: 1.8079217625199817e-05\n","Epoch 7401, Loss: 1.8001173884840682e-05\n","Epoch 7501, Loss: 1.776498174876906e-05\n","Epoch 7601, Loss: 1.7570357158547267e-05\n","Epoch 7701, Loss: 1.7434978872188367e-05\n","Epoch 7801, Loss: 1.7248012227355503e-05\n","Epoch 7901, Loss: 1.709269781713374e-05\n","Epoch 8001, Loss: 1.694363891147077e-05\n","Epoch 8101, Loss: 1.6794740076875314e-05\n","Epoch 8201, Loss: 1.695908395049628e-05\n","Epoch 8301, Loss: 1.6493415387230925e-05\n","Epoch 8401, Loss: 1.634984255360905e-05\n","Epoch 8501, Loss: 1.6258056348306127e-05\n","Epoch 8601, Loss: 1.6093330486910418e-05\n","Epoch 8701, Loss: 1.591997715877369e-05\n","Epoch 8801, Loss: 1.5794585124240257e-05\n","Epoch 8901, Loss: 1.5670062566641718e-05\n","Epoch 9001, Loss: 1.5554956917185336e-05\n","Epoch 9101, Loss: 1.5448804333573207e-05\n","Epoch 9201, Loss: 1.5342577171395533e-05\n","Epoch 9301, Loss: 1.5239540516631678e-05\n","Epoch 9401, Loss: 1.514650102762971e-05\n","Epoch 9501, Loss: 1.505292129877489e-05\n","Epoch 9601, Loss: 1.496471759310225e-05\n","Epoch 9701, Loss: 1.4880353774060495e-05\n","Epoch 9801, Loss: 1.5125968275242485e-05\n","Epoch 9901, Loss: 1.4723856111231726e-05\n","Epoch 10001, Loss: 1.4652539903181605e-05\n","Epoch 10101, Loss: 1.4576941794075537e-05\n","Epoch 10201, Loss: 1.4514689610223286e-05\n","Epoch 10301, Loss: 1.4444850421568844e-05\n","Epoch 10401, Loss: 1.438413073628908e-05\n","Epoch 10501, Loss: 1.4413267308555078e-05\n","Epoch 10601, Loss: 1.4420504157897085e-05\n","Epoch 10701, Loss: 1.4230971828510519e-05\n","Epoch 10801, Loss: 1.4165106222208124e-05\n","Epoch 10901, Loss: 1.4113110410107765e-05\n","Epoch 11001, Loss: 1.4236665265343618e-05\n","Epoch 11101, Loss: 1.4015808119438589e-05\n","Epoch 11201, Loss: 1.4047626791580115e-05\n","Epoch 11301, Loss: 1.3926526662544347e-05\n","Epoch 11401, Loss: 1.3906689673603978e-05\n","Epoch 11501, Loss: 1.3843233318766579e-05\n","Epoch 11601, Loss: 1.3832448530592956e-05\n","Epoch 11701, Loss: 1.4003571777720936e-05\n","Epoch 11801, Loss: 1.3723887605010532e-05\n","Epoch 11901, Loss: 1.3718491572944913e-05\n","Epoch 12001, Loss: 1.364944182569161e-05\n","Epoch 12101, Loss: 1.3604809282696806e-05\n","Epoch 12201, Loss: 1.3568344002123922e-05\n","Epoch 12301, Loss: 1.3532175216823816e-05\n","Epoch 12401, Loss: 1.3948781997896731e-05\n","Epoch 12501, Loss: 1.3466536984196864e-05\n","Epoch 12601, Loss: 1.342351060884539e-05\n","Epoch 12701, Loss: 1.3393312656262424e-05\n","Epoch 12801, Loss: 1.335341585217975e-05\n","Epoch 12901, Loss: 1.331931161985267e-05\n","Epoch 13001, Loss: 1.3284985470818356e-05\n","Epoch 13101, Loss: 1.326854635408381e-05\n","Epoch 13201, Loss: 1.3217690138844773e-05\n","Epoch 13301, Loss: 1.3186172509449534e-05\n","Epoch 13401, Loss: 1.3152752217138186e-05\n","Epoch 13501, Loss: 1.3136844245309476e-05\n","Epoch 13601, Loss: 1.3110014151607174e-05\n","Epoch 13701, Loss: 1.3055841009190772e-05\n","Epoch 13801, Loss: 1.3024213330936618e-05\n","Epoch 13901, Loss: 1.29928603200824e-05\n","Epoch 14001, Loss: 1.2961948414158542e-05\n","Epoch 14101, Loss: 1.2983115993847605e-05\n","Epoch 14201, Loss: 1.296082427870715e-05\n","Epoch 14301, Loss: 1.2869736565335188e-05\n","Epoch 14401, Loss: 1.284594509343151e-05\n","Epoch 14501, Loss: 1.2810257430828642e-05\n","Epoch 14601, Loss: 1.278346280741971e-05\n","Epoch 14701, Loss: 1.2751692338497378e-05\n","Epoch 14801, Loss: 1.2736841199512128e-05\n","Epoch 14901, Loss: 1.2699952094408218e-05\n","Epoch 15001, Loss: 1.2760478057316504e-05\n","Epoch 15101, Loss: 1.263800459128106e-05\n","Epoch 15201, Loss: 1.2611224519787356e-05\n","Epoch 15301, Loss: 1.2583764146256726e-05\n","Epoch 15401, Loss: 1.260465978702996e-05\n","Epoch 15501, Loss: 1.2529953892226331e-05\n","Epoch 15601, Loss: 1.2778114069078583e-05\n","Epoch 15701, Loss: 1.253049686056329e-05\n","Epoch 15801, Loss: 1.2748468179779593e-05\n","Epoch 15901, Loss: 1.2496132512751501e-05\n","Epoch 16001, Loss: 1.2998173588130157e-05\n","Epoch 16101, Loss: 1.2376239283184987e-05\n","Epoch 16201, Loss: 1.2351127224974334e-05\n","Epoch 16301, Loss: 1.2327562217251398e-05\n","Epoch 16401, Loss: 1.2308221812418196e-05\n","Epoch 16501, Loss: 1.2309638805163559e-05\n","Epoch 16601, Loss: 1.2255579349584877e-05\n","Epoch 16701, Loss: 1.230636644322658e-05\n","Epoch 16801, Loss: 1.3297541954671033e-05\n","Epoch 16901, Loss: 1.2185969353595283e-05\n","Epoch 17001, Loss: 1.217323551827576e-05\n","Epoch 17101, Loss: 1.2145024811616167e-05\n","Epoch 17201, Loss: 1.2120924111513887e-05\n","Epoch 17301, Loss: 1.2100763342459686e-05\n","Epoch 17401, Loss: 1.2096431419195142e-05\n","Epoch 17501, Loss: 1.2055949810019229e-05\n","Epoch 17601, Loss: 1.2227382285345811e-05\n","Epoch 17701, Loss: 1.2013070772809442e-05\n","Epoch 17801, Loss: 1.2001739378320053e-05\n","Epoch 17901, Loss: 1.1965641533606686e-05\n","Epoch 18001, Loss: 1.1945076039410196e-05\n","Epoch 18101, Loss: 1.1924878890567925e-05\n","Epoch 18201, Loss: 1.1911958608834539e-05\n","Epoch 18301, Loss: 1.194926880998537e-05\n","Epoch 18401, Loss: 1.1964783880102914e-05\n","Epoch 18501, Loss: 1.1848167559946887e-05\n","Epoch 18601, Loss: 1.1936269402212929e-05\n","Epoch 18701, Loss: 1.1806050679297186e-05\n","Epoch 18801, Loss: 1.178802085632924e-05\n","Epoch 18901, Loss: 1.2315364983805921e-05\n","Epoch 19001, Loss: 1.2138494639657438e-05\n","Epoch 19101, Loss: 1.1732010534615256e-05\n","Epoch 19201, Loss: 1.1717734196281526e-05\n","Epoch 19301, Loss: 1.1697686204570346e-05\n","Epoch 19401, Loss: 1.167923619505018e-05\n","Epoch 19501, Loss: 1.1663045370369218e-05\n","Epoch 19601, Loss: 1.1645323866105173e-05\n","Epoch 19701, Loss: 1.16381561383605e-05\n","Epoch 19801, Loss: 1.183895074063912e-05\n","Epoch 19901, Loss: 1.2309749763517175e-05\n"]}]},{"cell_type":"markdown","id":"c71626b5","metadata":{"id":"c71626b5"},"source":["## Step 2 Copy Network Weights to Shader"]},{"cell_type":"code","execution_count":null,"id":"34fcd78d","metadata":{"id":"34fcd78d"},"outputs":[],"source":["\n","\"\"\"\n","Run this step to generate the text file for the neural network weights.\n","The generated weights will be printed to the Notebook output.\n","There is no implementation requirement for this section.\n","\n","The neural SDF to ShaderToy conversion were modified based on Blackle Mori's Neural Stanford Bunny: https://www.shadertoy.com/view/wtVyWK\n","\"\"\"\n","\n","import re\n","\n","### Helper function for convert pytorch cuda tensor to numpy arrays\n","def dump_data(dat):\n","  dat = dat.cpu().detach().numpy()\n","  return dat\n","\n","### Print a vector to a form that's usable in fragement shader\n","def print_vec4(ws):\n","  vec = \"vec4(\" + \",\".join([\"{0:.2f}\".format(w) for w in ws]) + \")\"\n","  vec = re.sub(r\"\\b0\\.\", \".\", vec)\n","  return vec\n","\n","### Print a matrix to a form that's usable in fragement shader\n","def print_mat4(ws):\n","  mat = \"mat4(\" + \",\".join([\"{0:.2f}\".format(w) for w in np.transpose(ws).flatten()]) + \")\"\n","  mat = re.sub(r\"\\b0\\.\", \".\", mat)\n","  return mat\n","\n","### Since we know networks are just matrices and vectors, this function converts our network to matrices and vectors that\n","### can be compiled in fragement shader.\n","def serialize_to_shadertoy(network, varname):\n","  omega = network.w0\n","  chunks = int(network.hidden_features/4)\n","  lin = network.network[0].fc\n","  in_w = dump_data(lin.weight)\n","  in_bias = dump_data(lin.bias)\n","  om = omega\n","  for row in range(chunks):\n","    line = \"vec4 %s0_%d=sin(\" % (varname, row)\n","    for ft in range(network.in_features):\n","        feature = x_vec = in_w[row*4:(row+1)*4,ft]*om\n","        line += (\"p.%s*\" % [\"y\",\"z\",\"x\"][ft]) + print_vec4(feature) + \"+\"\n","    bias = in_bias[row*4:(row+1)*4]*om\n","    line += print_vec4(bias) + \");\"\n","    print(line)\n","\n","  #hidden layers\n","  for layer in range(network.hidden_layers):\n","    layer_w = dump_data(network.network[layer+1].fc.weight)\n","    layer_bias = dump_data(network.network[layer+1].fc.bias)\n","    for row in range(chunks):\n","      line = (\"vec4 %s%d_%d\" % (varname, layer+1, row)) + \"=sin(\"\n","      for col in range(chunks):\n","        mat = layer_w[row*4:(row+1)*4,col*4:(col+1)*4]*omega\n","        line += print_mat4(mat) + (\"*%s%d_%d\"%(varname, layer, col)) + \"+\\n    \"\n","      bias = layer_bias[row*4:(row+1)*4]*omega\n","      line += print_vec4(bias)+\")/%0.1f+%s%d_%d;\"%(sqrt(layer+1), varname, layer, row)\n","      print(line)\n","\n","  #output layer\n","  out_w = dump_data(network.network[-1].fc.weight)\n","  out_bias = dump_data(network.network[-1].fc.bias)\n","  for outf in range(network.out_features):\n","    line = \"return \"\n","    for row in range(chunks):\n","      vec = out_w[outf,row*4:(row+1)*4]\n","      line += (\"dot(%s%d_%d,\"%(varname, network.hidden_layers, row)) + print_vec4(vec) + \")+\\n    \"\n","    print(line + \"{:0.3f}\".format(out_bias[outf])+\";\")"]},{"cell_type":"code","execution_count":null,"id":"d0fcebc6-c43a-4ff9-9a5f-622be22d03cf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d0fcebc6-c43a-4ff9-9a5f-622be22d03cf","outputId":"c2f6b25f-ec3b-44b9-843d-f809c60e743e","executionInfo":{"status":"ok","timestamp":1739466861537,"user_tz":300,"elapsed":86,"user":{"displayName":"Jiayi Chen","userId":"08311739456871249100"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["vec4 f0_0=sin(p.y*vec4(-.62,-1.88,-4.48,2.80)+p.z*vec4(3.13,-4.22,-1.07,-2.99)+p.x*vec4(-1.89,3.14,1.64,-.28)+vec4(3.19,-.31,6.39,2.80));\n","vec4 f0_1=sin(p.y*vec4(-4.10,-1.45,1.77,1.69)+p.z*vec4(-4.73,1.28,-2.07,3.30)+p.x*vec4(2.55,1.73,-3.73,4.05)+vec4(8.06,-6.20,.58,-5.95));\n","vec4 f0_2=sin(p.y*vec4(-2.49,-3.30,1.02,-.29)+p.z*vec4(-1.14,-1.14,3.33,2.44)+p.x*vec4(3.77,.58,.26,-2.43)+vec4(1.01,-8.36,4.24,-4.98));\n","vec4 f0_3=sin(p.y*vec4(-3.04,3.29,.41,.81)+p.z*vec4(4.42,-1.19,-.70,1.32)+p.x*vec4(-4.45,.34,-1.39,-1.42)+vec4(2.59,7.37,-8.26,4.32));\n","vec4 f1_0=sin(mat4(-.14,.42,-.45,.24,.33,-.06,-.25,.33,.05,.44,.17,-.32,-.12,.62,-.28,-.26)*f0_0+\n","    mat4(.30,-.25,.15,.56,.84,-1.18,-.87,-.62,.31,-.14,.33,-.50,-.09,-.32,-.07,-.58)*f0_1+\n","    mat4(.40,-.06,.18,-.19,.66,.06,-.04,.43,-.40,-.39,.37,.12,-.16,-.41,.10,-.68)*f0_2+\n","    mat4(-.44,.23,-.22,-.15,-.15,.01,.54,.42,-.17,-.84,-.56,.71,-.05,-.22,-.33,-.95)*f0_3+\n","    vec4(3.05,.18,-3.37,3.69))/1.0+f0_0;\n","vec4 f1_1=sin(mat4(-.26,-.49,-.59,-.59,-.72,-.26,-.09,.36,.82,.27,-.09,.19,-.44,.19,-.15,.23)*f0_0+\n","    mat4(-.56,.27,.02,.88,-.93,-.09,-.23,-.83,-.23,.28,-.30,-.12,.67,.24,-.48,.56)*f0_1+\n","    mat4(.09,-.46,.07,-.36,-.10,.33,-1.66,.34,.62,-.35,-.08,-.43,-.44,-.25,.28,.05)*f0_2+\n","    mat4(-.09,.04,-.19,.42,-.54,.32,-.98,-.18,.15,.55,.97,-.35,-.08,.21,-.39,.15)*f0_3+\n","    vec4(1.70,-.83,1.23,-3.46))/1.0+f0_1;\n","vec4 f1_2=sin(mat4(-.11,-.69,-.59,-.14,-.42,-.06,-.14,-.57,.17,.34,.09,-.27,-.21,.07,.51,-.02)*f0_0+\n","    mat4(.30,-.24,-.71,-.28,.41,.41,-.62,.03,.02,.30,-.29,-.62,.74,.30,-.37,-.42)*f0_1+\n","    mat4(-.18,-.04,.17,-.30,.51,-.17,.38,-.27,.47,.25,-.01,-.72,-1.09,-.90,-.47,.33)*f0_2+\n","    mat4(-.18,.11,-.29,.08,-.31,.34,-.14,-.44,.04,-.70,.36,-.08,-.10,-.26,.04,.46)*f0_3+\n","    vec4(-2.37,1.16,.79,1.78))/1.0+f0_2;\n","vec4 f1_3=sin(mat4(.89,-.66,-.33,.45,-.50,-.38,-.20,.01,-.06,-.04,-.26,.17,-.48,.40,.51,-.32)*f0_0+\n","    mat4(.64,-.20,-.14,.23,.12,-1.02,-.87,-.08,.44,-.47,-.12,-.21,-.46,.45,-.20,-.13)*f0_1+\n","    mat4(.43,.00,.10,-.27,.24,-.52,.49,.06,.10,.58,-.62,.32,1.35,.13,.43,-.55)*f0_2+\n","    mat4(-.07,.04,-.52,-.24,.02,-.02,.34,-.10,.70,-.23,.46,.78,.15,.08,.43,.68)*f0_3+\n","    vec4(.39,2.25,-1.22,-1.66))/1.0+f0_3;\n","vec4 f2_0=sin(mat4(.09,.66,.98,1.06,-.41,.80,.75,.42,.59,.40,-.58,.52,.27,-.86,-.48,-.98)*f1_0+\n","    mat4(-.45,.83,.81,-.21,.85,1.28,-.56,.98,.56,.44,-.38,-.28,-.18,-.57,.18,-.25)*f1_1+\n","    mat4(-.33,-.19,.22,.15,.15,-1.19,-.55,1.01,-.41,.61,.82,-.20,-.31,.26,-.20,.48)*f1_2+\n","    mat4(-.17,-.53,-.22,-.12,.76,-.02,.08,.39,-.44,-.41,-.09,-.99,-.38,.58,-.47,.22)*f1_3+\n","    vec4(1.10,1.06,2.47,-2.90))/1.4+f1_0;\n","vec4 f2_1=sin(mat4(-1.18,-.16,-.63,-.81,-.00,-.45,-.50,-.91,.41,.55,.24,.66,.19,-.66,-.08,-.47)*f1_0+\n","    mat4(-.56,.46,-.52,1.01,.21,-.52,-.00,-.45,.58,-.12,.35,.10,.65,.10,-.32,-.57)*f1_1+\n","    mat4(-.51,.24,.02,-.29,.67,-.61,-.39,-.47,-.37,-.22,-1.06,.05,.27,-.27,-.75,.36)*f1_2+\n","    mat4(.82,.17,.25,-.23,-.07,-1.07,.59,.60,.83,.50,.42,.56,.29,.87,.61,.78)*f1_3+\n","    vec4(1.29,-3.61,3.17,-.25))/1.4+f1_1;\n","vec4 f2_2=sin(mat4(-.45,.25,-.25,-.25,.07,.30,-.25,.35,.16,-.96,-.08,1.09,.09,-.17,.11,.57)*f1_0+\n","    mat4(-.06,-.39,.41,.55,.51,-.36,.30,.28,-.19,-.45,.71,-.25,-.41,-.23,-.82,.98)*f1_1+\n","    mat4(.18,-.45,-.11,.29,-1.15,-1.12,.10,.74,-.28,-.25,.64,.35,-.09,.52,.16,-.28)*f1_2+\n","    mat4(-.44,-.31,-.14,.30,.19,.12,-.11,.33,-.67,-.58,-.73,.01,.40,.16,-.09,-.75)*f1_3+\n","    vec4(-.06,-3.38,-2.75,1.26))/1.4+f1_2;\n","vec4 f2_3=sin(mat4(.70,.26,.99,.65,-.45,.69,.25,-.09,.00,-.26,-.32,.67,-.82,-.47,.78,-.41)*f1_0+\n","    mat4(-.90,.16,-.23,.01,-1.09,.42,-.01,-.77,-.03,-.41,.15,-.74,-.49,-.80,-.16,-.03)*f1_1+\n","    mat4(.15,-.15,.60,.33,.31,-.35,.68,-.05,.03,.08,-.27,.46,.80,1.21,-.88,.47)*f1_2+\n","    mat4(.02,-.58,-.32,-.43,-.15,-.32,-1.00,.21,-1.27,-.95,-.57,.02,.10,.98,-1.31,.16)*f1_3+\n","    vec4(1.51,4.15,.87,4.02))/1.4+f1_3;\n","return dot(f2_0,vec4(-.08,-.05,.05,-.04))+\n","    dot(f2_1,vec4(-.04,.04,.03,-.03))+\n","    dot(f2_2,vec4(-.06,.10,.05,.05))+\n","    dot(f2_3,vec4(.04,-.08,-.05,-.07))+\n","    0.121;\n"]}],"source":["serialize_to_shadertoy(neural_sdf, 'f')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.16"}},"nbformat":4,"nbformat_minor":5}